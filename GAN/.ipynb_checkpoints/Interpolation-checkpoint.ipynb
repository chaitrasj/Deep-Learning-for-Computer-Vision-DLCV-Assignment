{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, epochs=200, img_size=28, latent_dim=100, lr=0.0002, name='traversal_gan')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################ HYPER PARAMETERS ###################\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--name\", type=str, default='traversal_gan', help=\"Name of image t show latent space traversal\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "transform_save = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(size=24),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "            # PYTORCH GITHUB MODEL\n",
    "        self.conv_1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1, bias=True), nn.LeakyReLU(negative_slope=0.2, inplace=True), nn.Dropout(0.4))\n",
    "        self.conv_2 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, bias=True), nn.LeakyReLU(negative_slope=0.2, inplace=True), nn.Dropout(0.4),nn.BatchNorm2d(32,0.8))\n",
    "        self.conv_3 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1, bias=True), nn.LeakyReLU(negative_slope=0.2, inplace=True), nn.Dropout(0.4),nn.BatchNorm2d(64,0.8))\n",
    "        self.conv_4 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1, bias=True), nn.LeakyReLU(negative_slope=0.2, inplace=True), nn.Dropout(0.4),nn.BatchNorm2d(128,0.8))\n",
    "        self.out = nn.Sequential(nn.Linear(in_features=512, out_features=1, bias=True), nn.Sigmoid())\n",
    "\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.conv_4(x)\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "############## BUILDING GENERATOR MODEL ####################\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = opt.img_size // 4\n",
    "        \n",
    "        self.dense = nn.Sequential(nn.Linear(in_features=latent_dim, out_features=128*(self.init_size**2), bias=True))\n",
    "        self.conv_1 = nn.Sequential(nn.BatchNorm2d(128), nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1, bias=True), nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n",
    "        self.conv_2 = nn.Sequential(nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1, bias=True), nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n",
    "        self.conv_3 = nn.Sequential(nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True), nn.Tanh())\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),128 ,self.init_size, self.init_size)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "###### DEFINING THE MODELS ######\n",
    "generator = Generator(opt.latent_dim)\n",
    "\n",
    "\n",
    "# Loading the pretrained Generator model\n",
    "checkpoint = torch.load('1_Model/Models/_150.pth.tar')\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    Tensor = torch.cuda.FloatTensor \n",
    "else:\n",
    "    Tensor = torch.FloatTensor\n",
    "    \n",
    "z = Tensor(np.random.normal(size = (25, opt.latent_dim)))\n",
    "gen_samples = generator(z)\n",
    "\n",
    "\n",
    "p1 = z[0]\n",
    "p2 = z[1]\n",
    "p3 = z[2]\n",
    "p4 = z[3]\n",
    "p5 = z[4]\n",
    "p6 = z[5]\n",
    "p7 = z[6]\n",
    "p8 = z[7]\n",
    "p9 = z[8]\n",
    "p10 = z[9]\n",
    "# p11 = z[10]\n",
    "# p12 = z[11]\n",
    "\n",
    "ratios = np.linspace(0, 1, num=100)\n",
    "vectors = list()\n",
    "\n",
    "# Doing Linear interpolation\n",
    "for i in range (9):\n",
    "    vectors.append(z[i])\n",
    "    for ratio in ratios:\n",
    "        vectors.append((1.0 - ratio) * z[i] + ratio * z[i+1])\n",
    "    vectors.append(z[i+1])\n",
    "\n",
    "\n",
    "vec = torch.stack(vectors)\n",
    "\n",
    "interpolate = generator(vec)\n",
    "\n",
    "x = torch.stack([transform_save(x_) for x_ in interpolate.cpu()])\n",
    "save_image(x, opt.name+'_%d.png' % 1, nrow=30, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
